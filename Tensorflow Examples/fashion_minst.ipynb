{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_minst.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqdvGTwtTSha",
        "colab_type": "code",
        "outputId": "79c79cb8-31b7-4cc8-dd23-6d5a7860e8d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMv3YqXmTTrJ",
        "colab_type": "code",
        "outputId": "6a531aa6-6e95-4b16-f0d4-c7c1caf8c813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=3)\n",
        "y_train = np.expand_dims(y_train, axis=3)\n",
        "x_test = np.expand_dims(x_test, axis=3)\n",
        "y_test = np.expand_dims(y_test, axis=3)\n",
        "\n",
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (60000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJ0kzmUTl2Q",
        "colab_type": "code",
        "outputId": "d46fd4a7-b164-479e-bcb1-726cfed60973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "\"\"\"\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "activation_fn = tf.nn.relu #tf.nn.elu\n",
        "n_filters = 128\n",
        "n_kernals = 3\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(28, 28, 1), name='img')\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, activation=activation_fn, padding='same')(inputs)\n",
        "#x = tf.keras.layers.Conv2D(2, 1, activation=activation_fn, padding='same')(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(128, activation=activation_fn)(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, predictions, name='toy_resnet')\n",
        "model.summary()\n",
        "\"\"\"\n",
        "\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "activation_fn = tf.nn.relu #tf.nn.elu\n",
        "regularization_fn = tf.keras.regularizers.l2\n",
        "n_filters = 256\n",
        "n_kernals = 3\n",
        "residual_tower_size = 2\n",
        "regularization_rate=1e-4\n",
        "\n",
        "inputs = tf.keras.Input(shape=(28, 28, 1), name='img')\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, kernel_regularizer=regularization_fn(regularization_rate), padding='same')(inputs)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "block_output = activation_fn(x)\n",
        "\n",
        "# Build residual tower\n",
        "for _ in range(residual_tower_size):\n",
        "    x = tf.keras.layers.Conv2D(n_filters, n_kernals, kernel_regularizer=regularization_fn(regularization_rate), padding='same')(block_output)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = activation_fn(x)\n",
        "    x = tf.keras.layers.Conv2D(n_filters, n_kernals, kernel_regularizer=regularization_fn(regularization_rate), padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.add([x, block_output])\n",
        "    block_output = activation_fn(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2D(2, 1, kernel_regularizer=regularization_fn(regularization_rate), padding='same')(block_output)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "#x = tf.keras.layers.Dense(256, kernel_regularizer=regularization_fn(regularization_rate))(x)\n",
        "#x = tf.keras.layers.BatchNormalization()(x)\n",
        "#x = activation_fn(x)\n",
        "#x = tf.keras.layers.Dropout(0.5)(x)\n",
        "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, predictions, name='toy_resnet')\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"toy_resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img (InputLayer)                [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 256)  2560        img[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 28, 28, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Relu_10 (TensorFlow [(None, 28, 28, 256) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 256)  590080      tf_op_layer_Relu_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 28, 28, 256)  1024        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Relu_11 (TensorFlow [(None, 28, 28, 256) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 28, 28, 256)  590080      tf_op_layer_Relu_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 28, 28, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 256)  0           batch_normalization_12[0][0]     \n",
            "                                                                 tf_op_layer_Relu_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Relu_12 (TensorFlow [(None, 28, 28, 256) 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 28, 28, 256)  590080      tf_op_layer_Relu_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 28, 28, 256)  1024        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Relu_13 (TensorFlow [(None, 28, 28, 256) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 28, 28, 256)  590080      tf_op_layer_Relu_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 256)  1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 256)  0           batch_normalization_14[0][0]     \n",
            "                                                                 tf_op_layer_Relu_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Relu_14 (TensorFlow [(None, 28, 28, 256) 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 28, 28, 2)    514         tf_op_layer_Relu_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 28, 28, 2)    8           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Relu_15 (TensorFlow [(None, 28, 28, 2)]  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1568)         0           tf_op_layer_Relu_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           15690       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,384,212\n",
            "Trainable params: 2,381,648\n",
            "Non-trainable params: 2,564\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGSAYrW5TpVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checkpoint_dir = './training_checkpoints'\n",
        "#checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "#checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
        "filepath = 'fashion_minst_ANN_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEAexamDTrNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf.random.set_seed(0)\n",
        "#model = tf.keras.models.load_model(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTTnmZTpTtqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9) #tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQI_bdjqTxSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#manager = tf.contrib.checkpoint.CheckpointManager(checkpoint, directory=\"/tmp/model\", max_to_keep=5)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                              patience=5, min_lr=0.00001)\n",
        "\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8), \n",
        "            tf.keras.callbacks.ModelCheckpoint(\n",
        "                filepath=filepath,\n",
        "                save_best_only=True,\n",
        "                monitor='val_loss',\n",
        "                verbose=1),\n",
        "            reduce_lr,\n",
        "            tensorboard_callback]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBBACxGZTyJE",
        "colab_type": "code",
        "outputId": "c2d9ee45-021b-4c23-8517-c0eaf1f87760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=100, validation_split=0.2, callbacks=callback)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.5382 - accuracy: 0.8446\n",
            "Epoch 00001: val_loss improved from inf to 0.46090, saving model to fashion_minst_ANN_model.h5\n",
            "48000/48000 [==============================] - 83s 2ms/sample - loss: 0.5380 - accuracy: 0.8447 - val_loss: 0.4609 - val_accuracy: 0.8688\n",
            "Epoch 2/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.4102 - accuracy: 0.8875\n",
            "Epoch 00002: val_loss improved from 0.46090 to 0.40212, saving model to fashion_minst_ANN_model.h5\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.4103 - accuracy: 0.8874 - val_loss: 0.4021 - val_accuracy: 0.8930\n",
            "Epoch 3/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.3650 - accuracy: 0.9025\n",
            "Epoch 00003: val_loss improved from 0.40212 to 0.37902, saving model to fashion_minst_ANN_model.h5\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.3650 - accuracy: 0.9025 - val_loss: 0.3790 - val_accuracy: 0.8996\n",
            "Epoch 4/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.3380 - accuracy: 0.9122\n",
            "Epoch 00004: val_loss improved from 0.37902 to 0.36559, saving model to fashion_minst_ANN_model.h5\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.3381 - accuracy: 0.9122 - val_loss: 0.3656 - val_accuracy: 0.9003\n",
            "Epoch 5/100\n",
            "47936/48000 [============================>.] - ETA: 0s - loss: 0.3153 - accuracy: 0.9191\n",
            "Epoch 00005: val_loss improved from 0.36559 to 0.35055, saving model to fashion_minst_ANN_model.h5\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.3153 - accuracy: 0.9190 - val_loss: 0.3506 - val_accuracy: 0.9075\n",
            "Epoch 6/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.2954 - accuracy: 0.9241\n",
            "Epoch 00006: val_loss did not improve from 0.35055\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2955 - accuracy: 0.9241 - val_loss: 0.3560 - val_accuracy: 0.9045\n",
            "Epoch 7/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.2818 - accuracy: 0.9283\n",
            "Epoch 00007: val_loss improved from 0.35055 to 0.34660, saving model to fashion_minst_ANN_model.h5\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2820 - accuracy: 0.9282 - val_loss: 0.3466 - val_accuracy: 0.9039\n",
            "Epoch 8/100\n",
            "47936/48000 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.9319\n",
            "Epoch 00008: val_loss did not improve from 0.34660\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2679 - accuracy: 0.9319 - val_loss: 0.3592 - val_accuracy: 0.9061\n",
            "Epoch 9/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.9361\n",
            "Epoch 00009: val_loss improved from 0.34660 to 0.33827, saving model to fashion_minst_ANN_model.h5\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2549 - accuracy: 0.9361 - val_loss: 0.3383 - val_accuracy: 0.9115\n",
            "Epoch 10/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.2430 - accuracy: 0.9388\n",
            "Epoch 00010: val_loss did not improve from 0.33827\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2430 - accuracy: 0.9389 - val_loss: 0.3425 - val_accuracy: 0.9068\n",
            "Epoch 11/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.2330 - accuracy: 0.9423\n",
            "Epoch 00011: val_loss did not improve from 0.33827\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2330 - accuracy: 0.9423 - val_loss: 0.3469 - val_accuracy: 0.9090\n",
            "Epoch 12/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.2232 - accuracy: 0.9454\n",
            "Epoch 00012: val_loss did not improve from 0.33827\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2232 - accuracy: 0.9454 - val_loss: 0.3615 - val_accuracy: 0.9075\n",
            "Epoch 13/100\n",
            "47936/48000 [============================>.] - ETA: 0s - loss: 0.2125 - accuracy: 0.9484\n",
            "Epoch 00013: val_loss did not improve from 0.33827\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2126 - accuracy: 0.9484 - val_loss: 0.3458 - val_accuracy: 0.9055\n",
            "Epoch 14/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.2021 - accuracy: 0.9512\n",
            "Epoch 00014: val_loss did not improve from 0.33827\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.2021 - accuracy: 0.9512 - val_loss: 0.3538 - val_accuracy: 0.9088\n",
            "Epoch 15/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.1484 - accuracy: 0.9733\n",
            "Epoch 00015: val_loss did not improve from 0.33827\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.1484 - accuracy: 0.9733 - val_loss: 0.3630 - val_accuracy: 0.9168\n",
            "Epoch 16/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9800\n",
            "Epoch 00016: val_loss did not improve from 0.33827\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.1298 - accuracy: 0.9800 - val_loss: 0.3750 - val_accuracy: 0.9167\n",
            "Epoch 17/100\n",
            "47968/48000 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 0.9828\n",
            "Epoch 00017: val_loss did not improve from 0.33827\n",
            "48000/48000 [==============================] - 82s 2ms/sample - loss: 0.1214 - accuracy: 0.9827 - val_loss: 0.3938 - val_accuracy: 0.9137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9618360b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scoDfef8T2fO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model = tf.keras.models.load_model(filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPSeqN2WT80U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fda45a34-0abc-4c42-bc9a-fc5f07b2ea49"
      },
      "source": [
        "model.evaluate(x_train,  y_train, verbose=2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 - 31s - loss: 0.2484 - accuracy: 0.9399\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2484153725941976, 0.93988335]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDQBeiS4T85-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "813ed157-7501-4e22-d06b-90416633e3c4"
      },
      "source": [
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 - 5s - loss: 0.3419 - accuracy: 0.9081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3418936897277832, 0.9081]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJuGzGVFT8-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e4d759b-d3f5-4446-d43e-c27f8fa6a5b6"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}