{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYv8ctD7GUMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP2de2YpGbKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5c6fb1b6-8ca9-4661-86b8-6250e807ac74"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "sample, sample_label = x_train[0], y_train[0]\n",
        "x_train.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI3Xo0llGrwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d6d8037-f4d0-4b5e-d756-f019896190ac"
      },
      "source": [
        "x_train = np.expand_dims(x_train, axis=3)\n",
        "#y_train = np.expand_dims(y_train, axis=3)\n",
        "x_test = np.expand_dims(x_test, axis=3)\n",
        "#y_test = np.expand_dims(y_test, axis=3)\n",
        "print(x_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxq1QxoAHs9z",
        "colab_type": "text"
      },
      "source": [
        "# CNN Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0O2SwcHG3Ws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f03d020-6b45-46d9-958d-9e646bd94d83"
      },
      "source": [
        "tf.random.set_seed(0)\n",
        "activation_fn = tf.nn.elu\n",
        "n_filters = 256\n",
        "n_kernals = 3\n",
        "\n",
        "encoder_input = tf.keras.Input(shape=(28, 28, 1), name='original_img')\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, activation=None, padding='same')(encoder_input)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "block_output = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, activation=None, padding='same')(block_output)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.add([x, block_output])\n",
        "x = activation_fn(x)\n",
        "\n",
        "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "block_output = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, activation=None, padding='same')(block_output)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.add([x, block_output])\n",
        "x = activation_fn(x)\n",
        "\n",
        "x = tf.keras.layers.MaxPooling2D(2)(x)\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "block_output = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, activation=None, padding='same')(block_output)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.add([x, block_output])\n",
        "x = activation_fn(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2D(1, 3, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "encoder_output = activation_fn(x)\n",
        "\"\"\"\n",
        "x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(784, activation=None)(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Dense(512, activation=None)(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Dense(256, activation=None)(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "encoder_output = activation_fn(x)\n",
        "\"\"\"\n",
        "#encoder_output = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "encoder = tf.keras.Model(encoder_input, encoder_output, name='encoder')\n",
        "encoder.summary()\n",
        "\"\"\"\n",
        "decoder_input = tf.keras.Input(shape=(256,), name='encoded_img')\n",
        "x = tf.keras.layers.Dense(256, activation=None)(decoder_input)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Dense(512, activation=None)(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Dense(784, activation=None)(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Reshape((7, 7, 16))(x)\n",
        "\"\"\"\n",
        "decoder_input = tf.keras.Input(shape=(7, 7, 1), name='encoded_img')\n",
        "#x = tf.keras.layers.Reshape((8, 8, 1))(decoder_input)\n",
        "x = tf.keras.layers.Conv2DTranspose(n_filters, n_kernals, activation=None, padding='same')(decoder_input)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "block_output = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(n_filters, n_kernals, activation=None, padding='same')(block_output)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(n_filters, n_kernals, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.add([x, block_output])\n",
        "x = activation_fn(x)\n",
        "\n",
        "x = tf.keras.layers.UpSampling2D(2)(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(n_filters, n_kernals, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "block_output = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(n_filters, n_kernals, activation=None, padding='same')(block_output)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(n_filters, n_kernals, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.add([x, block_output])\n",
        "x = activation_fn(x)\n",
        "\n",
        "x = tf.keras.layers.UpSampling2D(2)(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(n_filters, n_kernals, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "block_output = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(n_filters, n_kernals, activation=None, padding='same')(block_output)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = activation_fn(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(n_filters, n_kernals, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.add([x, block_output])\n",
        "x = activation_fn(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2DTranspose(1, 3, activation=None, padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "decoder_output = activation_fn(x)\n",
        "\n",
        "decoder = tf.keras.Model(decoder_input, decoder_output, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "autoencoder_input = tf.keras.Input(shape=(28, 28, 1), name='img')\n",
        "encoded_img = encoder(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = tf.keras.Model(autoencoder_input, decoded_img, name='autoencoder')\n",
        "autoencoder.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "original_img (InputLayer)       [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 28, 28, 256)  2560        original_img[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 28, 28, 256)  1024        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu (TensorFlowOpLa [(None, 28, 28, 256) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 28, 256)  590080      tf_op_layer_Elu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 28, 28, 256)  1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_1 (TensorFlowOp [(None, 28, 28, 256) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 28, 28, 256)  590080      tf_op_layer_Elu_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 28, 28, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 28, 28, 256)  0           batch_normalization_2[0][0]      \n",
            "                                                                 tf_op_layer_Elu[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_2 (TensorFlowOp [(None, 28, 28, 256) 0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 14, 14, 256)  0           tf_op_layer_Elu_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 14, 14, 256)  590080      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 14, 14, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_3 (TensorFlowOp [(None, 14, 14, 256) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 14, 14, 256)  590080      tf_op_layer_Elu_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 14, 14, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_4 (TensorFlowOp [(None, 14, 14, 256) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 14, 14, 256)  590080      tf_op_layer_Elu_4[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 14, 14, 256)  1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 14, 14, 256)  0           batch_normalization_5[0][0]      \n",
            "                                                                 tf_op_layer_Elu_3[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_5 (TensorFlowOp [(None, 14, 14, 256) 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 256)    0           tf_op_layer_Elu_5[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 7, 7, 256)    590080      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 7, 7, 256)    1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_6 (TensorFlowOp [(None, 7, 7, 256)]  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 7, 7, 256)    590080      tf_op_layer_Elu_6[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 7, 7, 256)    1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_7 (TensorFlowOp [(None, 7, 7, 256)]  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 7, 7, 256)    590080      tf_op_layer_Elu_7[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 7, 7, 256)    1024        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 7, 7, 256)    0           batch_normalization_8[0][0]      \n",
            "                                                                 tf_op_layer_Elu_6[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_8 (TensorFlowOp [(None, 7, 7, 256)]  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 7, 7, 1)      2305        tf_op_layer_Elu_8[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 7, 7, 1)      4           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_9 (TensorFlowOp [(None, 7, 7, 1)]    0           batch_normalization_9[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 4,734,725\n",
            "Trainable params: 4,730,115\n",
            "Non-trainable params: 4,610\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoded_img (InputLayer)        [(None, 7, 7, 1)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 7, 7, 256)    2560        encoded_img[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 7, 7, 256)    1024        conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_10 (TensorFlowO [(None, 7, 7, 256)]  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 7, 7, 256)    590080      tf_op_layer_Elu_10[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 7, 7, 256)    1024        conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_11 (TensorFlowO [(None, 7, 7, 256)]  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 7, 7, 256)    590080      tf_op_layer_Elu_11[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 7, 7, 256)    1024        conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 7, 7, 256)    0           batch_normalization_12[0][0]     \n",
            "                                                                 tf_op_layer_Elu_10[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_12 (TensorFlowO [(None, 7, 7, 256)]  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 14, 14, 256)  0           tf_op_layer_Elu_12[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 14, 14, 256)  590080      up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 14, 14, 256)  1024        conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_13 (TensorFlowO [(None, 14, 14, 256) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 14, 14, 256)  590080      tf_op_layer_Elu_13[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 14, 14, 256)  1024        conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_14 (TensorFlowO [(None, 14, 14, 256) 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 14, 14, 256)  590080      tf_op_layer_Elu_14[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 14, 14, 256)  1024        conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 14, 14, 256)  0           batch_normalization_15[0][0]     \n",
            "                                                                 tf_op_layer_Elu_13[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_15 (TensorFlowO [(None, 14, 14, 256) 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0           tf_op_layer_Elu_15[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 28, 28, 256)  590080      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 28, 28, 256)  1024        conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_16 (TensorFlowO [(None, 28, 28, 256) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 28, 28, 256)  590080      tf_op_layer_Elu_16[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 28, 28, 256)  1024        conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_17 (TensorFlowO [(None, 28, 28, 256) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTrans (None, 28, 28, 256)  590080      tf_op_layer_Elu_17[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 28, 28, 256)  1024        conv2d_transpose_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 256)  0           batch_normalization_18[0][0]     \n",
            "                                                                 tf_op_layer_Elu_16[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_18 (TensorFlowO [(None, 28, 28, 256) 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTrans (None, 28, 28, 1)    2305        tf_op_layer_Elu_18[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 28, 28, 1)    4           conv2d_transpose_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Elu_19 (TensorFlowO [(None, 28, 28, 1)]  0           batch_normalization_19[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 4,734,725\n",
            "Trainable params: 4,730,115\n",
            "Non-trainable params: 4,610\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 7, 7, 1)           4734725   \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 28, 28, 1)         4734725   \n",
            "=================================================================\n",
            "Total params: 9,469,450\n",
            "Trainable params: 9,460,230\n",
            "Non-trainable params: 9,220\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsRwmLXJG5r4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "60a6d5f3-1b5d-42f9-950a-974ccc52cd35"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "autoencoder.compile(optimizer, \n",
        "                    loss=tf.keras.losses.MeanSquaredError())\n",
        "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]\n",
        "autoencoder.fit(x_train, x_train, epochs=50, validation_split=0.2, batch_size=32, callbacks=callback)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/50\n",
            "48000/48000 [==============================] - 153s 3ms/sample - loss: 0.0161 - val_loss: 0.0081\n",
            "Epoch 2/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0072 - val_loss: 0.3798\n",
            "Epoch 3/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0058 - val_loss: 0.0063\n",
            "Epoch 4/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0037 - val_loss: 0.0030\n",
            "Epoch 5/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0039 - val_loss: 0.0028\n",
            "Epoch 6/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0027 - val_loss: 0.0031\n",
            "Epoch 7/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 8/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0038 - val_loss: 0.0034\n",
            "Epoch 9/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0028 - val_loss: 0.0023\n",
            "Epoch 10/50\n",
            "48000/48000 [==============================] - 142s 3ms/sample - loss: 0.0023 - val_loss: 0.0083\n",
            "Epoch 11/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0040 - val_loss: 0.0047\n",
            "Epoch 12/50\n",
            "48000/48000 [==============================] - 142s 3ms/sample - loss: 0.0026 - val_loss: 0.0020\n",
            "Epoch 13/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 14/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0019 - val_loss: 0.0108\n",
            "Epoch 15/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0022 - val_loss: 0.0031\n",
            "Epoch 16/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 17/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 18/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 19/50\n",
            "48000/48000 [==============================] - 143s 3ms/sample - loss: 0.0016 - val_loss: 0.0017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe386c372e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92YmbFJhHAaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "a834df96-57c9-467f-f20c-753339e924df"
      },
      "source": [
        "#tf.keras.models.save_model(autoencoder, 'autoencoder_model')\n",
        "autoencoder.save('autoencoder_model.ckpt')\n",
        "autoencoder.save_weights('autoencoder_weights.ckpt')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: autoencoder_model.ckpt/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT8aa_oMHAfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "00e2c362-aa27-4f18-9520-4381fb5eaef5"
      },
      "source": [
        "# Prediction on training\n",
        "autoencoder.evaluate(x_train, x_train, verbose=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 - 56s - loss: 0.0017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0016691987278560797"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3C6nMZ-HET2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8e766e3a-4d83-4a60-d3cc-4d100fa628d8"
      },
      "source": [
        "# Prediction on test\n",
        "autoencoder.evaluate(x_test,  x_test, verbose=2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 - 10s - loss: 0.0017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0017090695394203067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-wrWZkKHGwU",
        "colab_type": "text"
      },
      "source": [
        "# Test CNN Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6TiomTeHMFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auc_x_train = autoencoder.predict(x_train)\n",
        "auc_x_test = autoencoder.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb4aGVlPHQrt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c617ca88-fcc3-4f82-bdfd-8055e85fa0ef"
      },
      "source": [
        "tf.random.set_seed(0)\n",
        "activation_fn = tf.nn.relu #tf.nn.elu\n",
        "n_filters = 128\n",
        "n_kernals = 3\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(28, 28, 1), name='img')\n",
        "x = tf.keras.layers.Conv2D(n_filters, n_kernals, activation=activation_fn, padding='same')(inputs)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(128, activation=activation_fn)(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, predictions)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 28, 28, 128)       1280      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 100352)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               12845184  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 12,847,754\n",
            "Trainable params: 12,847,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wrRnhWmHdUq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a9bc6b04-9469-494b-ca04-e8fbd01b93ab"
      },
      "source": [
        "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)]\n",
        "model.fit(auc_x_train, y_train, epochs=100, validation_split=0.2, callbacks=callback)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/100\n",
            "48000/48000 [==============================] - 10s 212us/sample - loss: 0.1522 - accuracy: 0.9532 - val_loss: 0.0742 - val_accuracy: 0.9778\n",
            "Epoch 2/100\n",
            "48000/48000 [==============================] - 10s 206us/sample - loss: 0.0573 - accuracy: 0.9817 - val_loss: 0.0619 - val_accuracy: 0.9818\n",
            "Epoch 3/100\n",
            "48000/48000 [==============================] - 10s 204us/sample - loss: 0.0344 - accuracy: 0.9887 - val_loss: 0.0640 - val_accuracy: 0.9819\n",
            "Epoch 4/100\n",
            "48000/48000 [==============================] - 10s 204us/sample - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.0708 - val_accuracy: 0.9808\n",
            "Epoch 5/100\n",
            "48000/48000 [==============================] - 10s 207us/sample - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0650 - val_accuracy: 0.9843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe375222eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2AuzIYkHeBG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ab9fc3e6-50bf-47bd-982c-adebe059bf68"
      },
      "source": [
        "model.evaluate(auc_x_train,  y_train, verbose=2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 - 4s - loss: 0.0179 - accuracy: 0.9953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01786199189693131, 0.9953333]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0xhrg4QHgxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e9940b87-124b-4b48-98fc-fed9f0cb3647"
      },
      "source": [
        "model.evaluate(auc_x_test,  y_test, verbose=2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 - 1s - loss: 0.0625 - accuracy: 0.9842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.062492876395500024, 0.9842]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}