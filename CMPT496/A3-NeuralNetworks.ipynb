{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "#from statsmodels.api import datasets\n",
    "from sklearn import datasets ## Get dataset from sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeOwnerFlag</th>\n",
       "      <th>NumberCarsOwned</th>\n",
       "      <th>NumberChildrenAtHome</th>\n",
       "      <th>AreaCode</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Married</th>\n",
       "      <th>JobType</th>\n",
       "      <th>EducationType</th>\n",
       "      <th>Country</th>\n",
       "      <th>Income</th>\n",
       "      <th>AgeBracket</th>\n",
       "      <th>ChildrenFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeOwnerFlag  NumberCarsOwned  NumberChildrenAtHome  AreaCode  Sex  \\\n",
       "0              1                0                     0       500    1   \n",
       "1              0                1                     3       500    1   \n",
       "2              1                1                     3       500    1   \n",
       "3              0                1                     0       500    0   \n",
       "4              1                4                     5       500    0   \n",
       "\n",
       "   Married  JobType  EducationType  Country  Income  AgeBracket  ChildrenFlag  \n",
       "0        1        0              0        1       3           0             1  \n",
       "1        0        0              0        1       3           1             1  \n",
       "2        1        0              0        1       2           1             1  \n",
       "3        0        0              0        1       2           0             0  \n",
       "4        0        0              0        1       2           0             1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikesData = pd.read_csv('BikesProcessed.csv')\n",
    "Labels = bikesData['BikeBuyer']\n",
    "bikesData.drop(bikesData.columns[0], axis=1, inplace=True)\n",
    "bikesData.drop(['BikeBuyer'], axis=1, inplace=True)\n",
    "Features = np.array(bikesData)\n",
    "print(Features.shape)\n",
    "bikesData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4095\n"
     ]
    }
   ],
   "source": [
    "feature_combs = []\n",
    "\n",
    "for i in range(1, 13):\n",
    "    feature_combs.extend(list(itertools.combinations(list(bikesData), i)))         \n",
    "print(len(feature_combs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grahamcooper/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#print(\"Training Set %\\t Test Set %\\t Features\")\n",
    "size = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "nr.seed(1115)\n",
    "for comb in feature_combs:\n",
    "    comb_features = np.array(bikesData[np.array(comb)])\n",
    "    indx = range(comb_features.shape[0])\n",
    "    indx = ms.train_test_split(indx, test_size = 5000, random_state=0)\n",
    "    X_train = comb_features[indx[0],:]\n",
    "    y_train = np.ravel(Labels[indx[0]])\n",
    "    X_test = comb_features[indx[1],:]\n",
    "    y_test = np.ravel(Labels[indx[1]])\n",
    "    \n",
    "    #print(bikesData[list(comb)])\n",
    "    #X_train, X_test, y_train, y_test = ms.train_test_split(\n",
    "    #    bikesData[list(comb)], Labels)\n",
    "    \n",
    "    #Rescale numeric features\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    nn_mod = MLPClassifier(random_state=0)\n",
    "    nn_mod.fit(X_train, y_train)\n",
    "    #print(\"%f\" % nn_mod.score(X_train, y_train), \"\\t %f\" % nn_mod.score(X_test, y_test), \"\\t\", comb)\n",
    "    train_scores.append(nn_mod.score(X_train, y_train))\n",
    "    test_scores.append(nn_mod.score(X_test, y_test))\n",
    "    size.append(len(comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "midx = pd.DataFrame()\n",
    "midx['size'] = size\n",
    "midx['train_scores'] = train_scores\n",
    "midx['test_scores'] = test_scores\n",
    "midx['combs'] = feature_combs\n",
    "midx.to_csv('NeuralNetwork.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp_Labels = Labels[Labels == 1] \n",
    "temp_Features = Features[Labels == 1,:]\n",
    "temp_Features = np.concatenate((Features, temp_Features), axis = 0)\n",
    "temp_Labels = np.concatenate((Labels, temp_Labels), axis = 0) \n",
    "\n",
    "print(temp_Features.shape)\n",
    "print(temp_Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Rescale numeric features\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train.shape)\n",
    "X_train[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=3, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=3, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {#\"alpha\":[0.0000001,0.000001,0.00001], \n",
    "              #\"early_stopping\":[True, False], \n",
    "              \"beta_1\":[0.95,0.90,0.80], \n",
    "              \"beta_2\":[0.999,0.9,0.8]}\n",
    "\n",
    "## Define the Neural Network model\n",
    "nn_clf = MLPClassifier(hidden_layer_sizes = (100,100),\n",
    "                       max_iter=300)\n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "nr.seed(3456)\n",
    "nn_clf = ms.GridSearchCV(estimator = nn_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'recall',\n",
    "                      return_train_score = True)\n",
    "\n",
    "nr.seed(6677)\n",
    "nn_clf.fit(Features, Labels)\n",
    "#print(nn_clf.best_estimator_.alpha)\n",
    "#print(nn_clf.best_estimator_.early_stopping)\n",
    "print(nn_clf.best_estimator_.beta_1)\n",
    "print(nn_clf.best_estimator_.beta_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(nn_clf, Features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly sample cases to create independent training and test data\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 5000)\n",
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])\n",
    "\n",
    "#Rescale numeric features\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train.shape)\n",
    "X_train[:5,:]\n",
    "\n",
    "## Oversample the minority case for the training data\n",
    "#y_temp = y_train[y_train == 1] \n",
    "#X_temp = X_train[y_train == 1,:]\n",
    "#X_train = np.concatenate((X_train, X_temp), axis = 0)\n",
    "#y_train = np.concatenate((y_train, y_temp), axis = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nr.seed(1115)\n",
    "nn_mod = MLPClassifier(hidden_layer_sizes = (100,100), \n",
    "                       #alpha = nn_clf.best_estimator_.alpha, \n",
    "                       #early_stopping = nn_clf.best_estimator_.early_stopping, \n",
    "                       beta_1 = nn_clf.best_estimator_.beta_1, \n",
    "                       beta_2 = nn_clf.best_estimator_.beta_2,\n",
    "                       max_iter = 300)\n",
    "nn_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = nn_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
