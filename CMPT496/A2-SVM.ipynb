{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, preprocessing\n",
    "#from statsmodels.api import datasets\n",
    "from sklearn import datasets ## Get dataset from sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16404, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeOwnerFlag</th>\n",
       "      <th>NumberCarsOwned</th>\n",
       "      <th>NumberChildrenAtHome</th>\n",
       "      <th>AreaCode</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Married</th>\n",
       "      <th>JobType</th>\n",
       "      <th>EducationType</th>\n",
       "      <th>Country</th>\n",
       "      <th>Income</th>\n",
       "      <th>AgeBracket</th>\n",
       "      <th>ChildrenFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomeOwnerFlag  NumberCarsOwned  NumberChildrenAtHome  AreaCode  Sex  \\\n",
       "0              1                0                     0       500    1   \n",
       "1              0                1                     3       500    1   \n",
       "2              1                1                     3       500    1   \n",
       "3              0                1                     0       500    0   \n",
       "4              1                4                     5       500    0   \n",
       "\n",
       "   Married  JobType  EducationType  Country  Income  AgeBracket  ChildrenFlag  \n",
       "0        1        0              0        1       3           0             1  \n",
       "1        0        0              0        1       3           1             1  \n",
       "2        1        0              0        1       2           1             1  \n",
       "3        0        0              0        1       2           0             0  \n",
       "4        0        0              0        1       2           0             1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikesData = pd.read_csv('BikesProcessed.csv')\n",
    "Labels = bikesData['BikeBuyer']\n",
    "bikesData.drop(bikesData.columns[0], axis=1, inplace=True)\n",
    "bikesData.drop(['BikeBuyer'], axis=1, inplace=True)\n",
    "Features = np.array(bikesData)\n",
    "print(Features.shape)\n",
    "bikesData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly sample cases to create independent training and test data\n",
    "\n",
    "nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 5000)\n",
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Rescale numeric features\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train.shape)\n",
    "X_train[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"kernal\\t C\\t gamma\\t Training Set %\\t Test Set %\")\n",
    "for c in [0.1, 1, 100]:\n",
    "    for g in [0.1, 1, 10]:\n",
    "        for k in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "            svm_mod = svm.SVC(kernel=k, C=c, gamma=g)\n",
    "            svm_mod.fit(X_train, y_train)\n",
    "            print(k, \"\\t\", c, \"\\t\", g, \"\\t %f\" % svm_mod.score(X_train, y_train), \"\\t %f\" % svm_mod.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"C\\t gamma\\t Training Set %\\t Test Set %\")\n",
    "for c in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "    for g in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        svm_mod = svm.SVC(kernel='rbf', C=c, gamma=g)\n",
    "        svm_mod.fit(X_train, y_train)\n",
    "        print(c, \"\\t\", g, \"\\t %f\" % svm_mod.score(X_train, y_train), \"\\t %f\" % svm_mod.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a tree and compute the feature importances\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "importances = tree.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, bikesData.columns[int(indices[f])], importances[indices[f]]))\n",
    "\n",
    "print('\\n')\n",
    "print(\"accuracy on training set: %f\" % tree.score(X_train, y_train))\n",
    "print(\"accuracy on test set: %f\" % tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested cross validation\n",
    "Code below based on:\n",
    "https://www.edx.org/course/principles-of-machine-learning-python-edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nr.seed(123)\n",
    "inside = ms.KFold(n_splits=2, shuffle = True)\n",
    "#nr.seed(321)\n",
    "outside = ms.KFold(n_splits=2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nr.seed(3456)\n",
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"C\": [0.1, 1, 100], \"gamma\":[0.1, 1, 10]}\n",
    "## Define the SVM model\n",
    "svc_clf = svm.SVC() #class_weight = {0:0.33, 1:0.67}\n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "clf = ms.GridSearchCV(estimator = svc_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "clf.fit(Features, Labels)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(clf, Features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly sample cases to create independent training and test data\n",
    "#nr.seed(1115)\n",
    "indx = range(Features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 5000)\n",
    "X_train = Features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = Features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Rescale numeric features\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nr.seed(1115)\n",
    "svm_mod = svm.SVC(C = clf.best_estimator_.C,\n",
    "                  gamma = clf.best_estimator_.gamma,\n",
    "                  #class_weight = {0:0.33, 1:0.67},\n",
    "                  probability=True) \n",
    "svm_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = svm_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds the best features for predicting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4095\n"
     ]
    }
   ],
   "source": [
    "feature_combs = []\n",
    "\n",
    "for i in range(1, 13):\n",
    "    feature_combs.extend(list(itertools.combinations(list(bikesData), i)))         \n",
    "print(len(feature_combs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set %\t Test Set %\t Features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/grahamcooper/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set %\\t Test Set %\\t Features\")\n",
    "size = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "nr.seed(1115)\n",
    "for comb in feature_combs:\n",
    "    comb_features = np.array(bikesData[np.array(comb)])\n",
    "    indx = range(comb_features.shape[0])\n",
    "    indx = ms.train_test_split(indx, test_size = 5000, random_state=0)\n",
    "    X_train = comb_features[indx[0],:]\n",
    "    y_train = np.ravel(Labels[indx[0]])\n",
    "    X_test = comb_features[indx[1],:]\n",
    "    y_test = np.ravel(Labels[indx[1]])\n",
    "    \n",
    "    #print(bikesData[list(comb)])\n",
    "    #X_train, X_test, y_train, y_test = ms.train_test_split(\n",
    "    #    bikesData[list(comb)], Labels)\n",
    "    \n",
    "    #Rescale numeric features\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    svm_mod = svm.SVC(random_state=0)\n",
    "    svm_mod.fit(X_train, y_train)\n",
    "    #print(\"%f\" % svm_mod.score(X_train, y_train), \"\\t %f\" % svm_mod.score(X_test, y_test), \"\\t\", comb)\n",
    "    train_scores.append(svm_mod.score(X_train, y_train))\n",
    "    test_scores.append(svm_mod.score(X_test, y_test))\n",
    "    size.append(len(comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "midx = pd.DataFrame()\n",
    "midx['size'] = size\n",
    "midx['train_scores'] = train_scores\n",
    "midx['test_scores'] = test_scores\n",
    "midx['combs'] = feature_combs\n",
    "midx.to_csv('SVM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "midx_size = pd.DataFrame()\n",
    "midx_size['size'] = size\n",
    "\n",
    "midx_train = pd.DataFrame()\n",
    "midx_train['train_scores'] = train_scores\n",
    "\n",
    "midx_test = pd.DataFrame()\n",
    "midx_test['test_scores'] = test_scores\n",
    "\n",
    "midx_combs = pd.DataFrame()\n",
    "midx_combs['combs'] = feature_combs\n",
    "\n",
    "midx = pd.concat([midx_size, midx_train, midx_test, midx_combs], ignore_index=True, axis=1)\n",
    "\n",
    "midx.to_csv('SVM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(pd.Series(test_scores, index=feature_combs)\n",
    "   .nlargest(10)\n",
    "   .plot(kind='barh')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested cross validation\n",
    "Code below based on:\n",
    "https://www.edx.org/course/principles-of-machine-learning-python-edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chosen_features = bikesData[['HomeOwnerFlag', 'Sex', 'Married', 'JobType', 'EducationType', 'Income', 'AgeBracket', 'ChildrenFlag', 'OnePlusCarsFlag']]\n",
    "chosen_features = np.array(chosen_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nr.seed(123)\n",
    "inside = ms.KFold(n_splits=2, shuffle = True)\n",
    "#nr.seed(321)\n",
    "outside = ms.KFold(n_splits=2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nr.seed(3456)\n",
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100], \"gamma\":[0.1, 1, 10, 100]}\n",
    "## Define the SVM model\n",
    "svc_clf = svm.SVC() #class_weight = {0:0.33, 1:0.67}\n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "clf = ms.GridSearchCV(estimator = svc_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "clf.fit(chosen_features, Labels)\n",
    "print(clf.best_estimator_.C)\n",
    "print(clf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(clf, chosen_features, Labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly sample cases to create independent training and test data\n",
    "#nr.seed(1115)\n",
    "indx = range(chosen_features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 5000)\n",
    "X_train = chosen_features[indx[0],:]\n",
    "y_train = np.ravel(Labels[indx[0]])\n",
    "X_test = chosen_features[indx[1],:]\n",
    "y_test = np.ravel(Labels[indx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Rescale numeric features\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nr.seed(1115)\n",
    "svm_mod = svm.SVC(C = clf.best_estimator_.C,\n",
    "                  gamma = clf.best_estimator_.gamma,\n",
    "                  #class_weight = {0:0.33, 1:0.67},\n",
    "                  probability=True) \n",
    "svm_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = svm_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
